[
    {
        "label": "Elasticsearch",
        "importPath": "elasticsearch",
        "description": "elasticsearch",
        "isExtraImport": true,
        "detail": "elasticsearch",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "io",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "io",
        "description": "io",
        "detail": "io",
        "documentation": {}
    },
    {
        "label": "abspath",
        "importPath": "os.path",
        "description": "os.path",
        "isExtraImport": true,
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Flask",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "flash",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "redirect",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "render_template",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "request",
        "importPath": "flask",
        "description": "flask",
        "isExtraImport": true,
        "detail": "flask",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "secure_filename",
        "importPath": "werkzeug.utils",
        "description": "werkzeug.utils",
        "isExtraImport": true,
        "detail": "werkzeug.utils",
        "documentation": {}
    },
    {
        "label": "shape",
        "importPath": "numpy.core.fromnumeric",
        "description": "numpy.core.fromnumeric",
        "isExtraImport": true,
        "detail": "numpy.core.fromnumeric",
        "documentation": {}
    },
    {
        "label": "imag",
        "importPath": "numpy.lib.type_check",
        "description": "numpy.lib.type_check",
        "isExtraImport": true,
        "detail": "numpy.lib.type_check",
        "documentation": {}
    },
    {
        "label": "dt",
        "kind": 5,
        "importPath": "dummy",
        "description": "dummy",
        "peekOfCode": "dt = {'77': \"< FileStorage: 'download (4).jpeg' ('image/jpeg')} >\",\n      '173': \"< FileStorage: 'download (5).jpeg' ('image/jpeg') > \",\n      '3': \"< FileStorage: 'images.jpeg' ('image/jpeg') > \"}\nfor i in dt:\n    print(i)",
        "detail": "dummy",
        "documentation": {}
    },
    {
        "label": "es",
        "kind": 5,
        "importPath": "elasticsea",
        "description": "elasticsea",
        "peekOfCode": "es = Elasticsearch(HOST='http://localhost', port=9200)  # for local instance\nes = Elasticsearch()\n# es.indices.create(index='data', ignore=400)  # creating first index\n# es.indices.exists(index='first')  # returns true if index exists\nes.indices.delete(index='data')  # deletes the index\n# adding data to elasticsearch\ndoc1 = {\"city\": \"new delhi\", \"country\": \"india\"}\ndoc2 = {\"city\": \"paris\", \"country\": \"england\"}\ndoc3 = {\"city\": \"california\", \"country\": \"usa\"}\n# >> > es.index(index=\"cities\", doc_type='places', id=1, body=doc1)",
        "detail": "elasticsea",
        "documentation": {}
    },
    {
        "label": "es",
        "kind": 5,
        "importPath": "elasticsea",
        "description": "elasticsea",
        "peekOfCode": "es = Elasticsearch()\n# es.indices.create(index='data', ignore=400)  # creating first index\n# es.indices.exists(index='first')  # returns true if index exists\nes.indices.delete(index='data')  # deletes the index\n# adding data to elasticsearch\ndoc1 = {\"city\": \"new delhi\", \"country\": \"india\"}\ndoc2 = {\"city\": \"paris\", \"country\": \"england\"}\ndoc3 = {\"city\": \"california\", \"country\": \"usa\"}\n# >> > es.index(index=\"cities\", doc_type='places', id=1, body=doc1)\n# >> > es.index(index=\"cities\", doc_type='places', id=2, body=doc2)",
        "detail": "elasticsea",
        "documentation": {}
    },
    {
        "label": "doc1",
        "kind": 5,
        "importPath": "elasticsea",
        "description": "elasticsea",
        "peekOfCode": "doc1 = {\"city\": \"new delhi\", \"country\": \"india\"}\ndoc2 = {\"city\": \"paris\", \"country\": \"england\"}\ndoc3 = {\"city\": \"california\", \"country\": \"usa\"}\n# >> > es.index(index=\"cities\", doc_type='places', id=1, body=doc1)\n# >> > es.index(index=\"cities\", doc_type='places', id=2, body=doc2)\n# >> > es.index(index=\"cities\", doc_type='places', id=3, body=doc3)\n# finding result related to particular index\n# >>> res=es.get(index='cities',doc_type=\"places\",id=3,body=doc3)\n# >>>res\n# >>> res['_source'] -->  {'city': 'california', 'country': 'usa'}",
        "detail": "elasticsea",
        "documentation": {}
    },
    {
        "label": "doc2",
        "kind": 5,
        "importPath": "elasticsea",
        "description": "elasticsea",
        "peekOfCode": "doc2 = {\"city\": \"paris\", \"country\": \"england\"}\ndoc3 = {\"city\": \"california\", \"country\": \"usa\"}\n# >> > es.index(index=\"cities\", doc_type='places', id=1, body=doc1)\n# >> > es.index(index=\"cities\", doc_type='places', id=2, body=doc2)\n# >> > es.index(index=\"cities\", doc_type='places', id=3, body=doc3)\n# finding result related to particular index\n# >>> res=es.get(index='cities',doc_type=\"places\",id=3,body=doc3)\n# >>>res\n# >>> res['_source'] -->  {'city': 'california', 'country': 'usa'}\n# chapter-3 search queries for matching documents:",
        "detail": "elasticsea",
        "documentation": {}
    },
    {
        "label": "doc3",
        "kind": 5,
        "importPath": "elasticsea",
        "description": "elasticsea",
        "peekOfCode": "doc3 = {\"city\": \"california\", \"country\": \"usa\"}\n# >> > es.index(index=\"cities\", doc_type='places', id=1, body=doc1)\n# >> > es.index(index=\"cities\", doc_type='places', id=2, body=doc2)\n# >> > es.index(index=\"cities\", doc_type='places', id=3, body=doc3)\n# finding result related to particular index\n# >>> res=es.get(index='cities',doc_type=\"places\",id=3,body=doc3)\n# >>>res\n# >>> res['_source'] -->  {'city': 'california', 'country': 'usa'}\n# chapter-3 search queries for matching documents:\n# '''",
        "detail": "elasticsea",
        "documentation": {}
    },
    {
        "label": "allowed_file",
        "kind": 2,
        "importPath": "flask_api",
        "description": "flask_api",
        "peekOfCode": "def allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n@app.route('/')\ndef upload_form():\n    return render_template('upload.html')\n@app.route('/', methods=['POST'])\ndef upload_image():\n    def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n        dim = None\n        (h, w) = image.shape[:2]",
        "detail": "flask_api",
        "documentation": {}
    },
    {
        "label": "upload_form",
        "kind": 2,
        "importPath": "flask_api",
        "description": "flask_api",
        "peekOfCode": "def upload_form():\n    return render_template('upload.html')\n@app.route('/', methods=['POST'])\ndef upload_image():\n    def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n        dim = None\n        (h, w) = image.shape[:2]\n        if width is None and height is None:\n            return image\n        if width is None:",
        "detail": "flask_api",
        "documentation": {}
    },
    {
        "label": "upload_image",
        "kind": 2,
        "importPath": "flask_api",
        "description": "flask_api",
        "peekOfCode": "def upload_image():\n    def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n        dim = None\n        (h, w) = image.shape[:2]\n        if width is None and height is None:\n            return image\n        if width is None:\n            r = height / float(h)\n            dim = (int(w * r), height)\n        else:",
        "detail": "flask_api",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "flask_api",
        "description": "flask_api",
        "peekOfCode": "app = Flask(__name__)\nALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n@app.route('/')\ndef upload_form():\n    return render_template('upload.html')\n@app.route('/', methods=['POST'])\ndef upload_image():\n    def resize(image, width=None, height=None, inter=cv2.INTER_AREA):",
        "detail": "flask_api",
        "documentation": {}
    },
    {
        "label": "ALLOWED_EXTENSIONS",
        "kind": 5,
        "importPath": "flask_api",
        "description": "flask_api",
        "peekOfCode": "ALLOWED_EXTENSIONS = set(['png', 'jpg', 'jpeg'])\ndef allowed_file(filename):\n    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n@app.route('/')\ndef upload_form():\n    return render_template('upload.html')\n@app.route('/', methods=['POST'])\ndef upload_image():\n    def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n        dim = None",
        "detail": "flask_api",
        "documentation": {}
    },
    {
        "label": "img",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "img = cv2.imread('img2.jpeg')  # image read\nimg2 = cv2.imread(\n    r'/home/admin1/Desktop/visibility score/Blur-Detection-Web-App/images/img1.jpeg')  # from other path\ncv2.imshow('opimage', img)  # image display\ncv2.imshow(\"secondop\", img2)\n# kisi key ka interrupt jab tak nahi hota tab tak ye band nahi hota\n'''\n# wrinting into an image\n'''\nsample = cv2.imread('sample.jpg')",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "img2",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "img2 = cv2.imread(\n    r'/home/admin1/Desktop/visibility score/Blur-Detection-Web-App/images/img1.jpeg')  # from other path\ncv2.imshow('opimage', img)  # image display\ncv2.imshow(\"secondop\", img2)\n# kisi key ka interrupt jab tak nahi hota tab tak ye band nahi hota\n'''\n# wrinting into an image\n'''\nsample = cv2.imread('sample.jpg')\ncv2.imshow('sampleop', sample)  # sample",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\ncv2.imshow('sampleop', sample)  # sample\ncv2.imwrite('newsample.jpg', sample)  # clone image into different format\ncv2.imwrite('newsample.png', sample)\ncv2.waitKey(0)\ncv2.destroyAllWindows()  # pure pop ups kill karta hai\n'''\n'''# getting image info\nsample = cv2.imread('sample.jpg')\ncv2.imshow('sampleop', sample)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\ncv2.imshow('sampleop', sample)\ninfo = sample.shape  # returns tuple\nprint(info)\nprint(type(info))\nprint(\"height pixel values-->\", info[0])\nprint(\"width pixel values -->\", info[1])\nprint(\"image plane-->\", info[2])\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "info",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "info = sample.shape  # returns tuple\nprint(info)\nprint(type(info))\nprint(\"height pixel values-->\", info[0])\nprint(\"width pixel values -->\", info[1])\nprint(\"image plane-->\", info[2])\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# convert colored images into greyscale images",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\ncv2.imshow('sampleop', sample)\ngrey_img = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\ncv2.imshow('grey_img_op', grey_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# convert RGB to Binary Image\n'''\n# why need to use greyscale image--> colored image is complex to peocess..the rgb colors overlaps over other",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "grey_img",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "grey_img = cv2.cvtColor(sample, cv2.COLOR_BGR2GRAY)\ncv2.imshow('grey_img_op', grey_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# convert RGB to Binary Image\n'''\n# why need to use greyscale image--> colored image is complex to peocess..the rgb colors overlaps over other\nsample = cv2.imread('sample.jpg', 0)\ncv2.imshow(\"grey\", sample)  # converted to greyscale image",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg', 0)\ncv2.imshow(\"grey\", sample)  # converted to greyscale image\n# we use threshhold..if value of pixal is less than threshold then it is black, if above its white\n# params-->src, thresh, maxval, type, dst=...)\ncv2.waitKey(0)\nret, bw = cv2.threshold(sample, 127, 255, cv2.THRESH_BINARY)\ncv2.imshow(\"binary\", bw)\nprint(ret)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nimg_hsv = cv2.cvtColor(sample, cv2.COLOR_BGR2HSV)\ncv2.imshow(\"hsv_image\", img_hsv)\ncv2.imshow(\"hue channel\", img_hsv[:, :, 0])\ncv2.imshow(\"saturation\", img_hsv[:, :, 1])\ncv2.imshow(\"value channel\", img_hsv[:, :, 2])\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Extract RGB Color Space",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "img_hsv",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "img_hsv = cv2.cvtColor(sample, cv2.COLOR_BGR2HSV)\ncv2.imshow(\"hsv_image\", img_hsv)\ncv2.imshow(\"hue channel\", img_hsv[:, :, 0])\ncv2.imshow(\"saturation\", img_hsv[:, :, 1])\ncv2.imshow(\"value channel\", img_hsv[:, :, 2])\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Extract RGB Color Space\n'''sample = cv2.imread('sample.jpg')",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "'''sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "'''sample = cv2.imread('sample.jpg')\ncv2.imshow('op', sample)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\nB, G, R = cv2.split(sample)\n# apne imahge ka matrix tayar karke..taki masking kr sake\nzeros = np.zeros(sample.shape[:2], dtype=\"uint8\")\ncv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "zeros",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "zeros = np.zeros(sample.shape[:2], dtype=\"uint8\")\ncv2.imshow(\"Red\", cv2.merge([zeros, zeros, R]))\ncv2.waitKey(0)\ncv2.destroyAllWindows()\ncv2.imshow(\"green\", cv2.merge([zeros, G, zeros]))\ncv2.waitKey(0)\ncv2.destroyAllWindows()\ncv2.imshow(\"blue\", cv2.merge([B, zeros, zeros]))\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nprint(sample.shape)  # get height and width\nheight, width = sample.shape[:2]\nprint(height)\nprint(width)\nquarter_height, quarter_width = height/5, width/5\nprint(quarter_height)\nprint(quarter_width)\nt = np.float32([[1, 0, quarter_height], [0, 1, quarter_width]])\nprint(t)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "t",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "t = np.float32([[1, 0, quarter_height], [0, 1, quarter_width]])\nprint(t)\n# warpaffine - -> width ans height are dicto exact - -> linear images-->height and width pixals are parallel to rach other\n# non-warpaffine - -> thoda tilt ho sakta hai--> non linear images\nimg_tranlation = cv2.warpAffine(sample, t, (width, height))\ncv2.imshow(\"original image\", sample)\ncv2.imshow(\"translation_image->\", img_tranlation)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "img_tranlation",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "img_tranlation = cv2.warpAffine(sample, t, (width, height))\ncv2.imshow(\"original image\", sample)\ncv2.imshow(\"translation_image->\", img_tranlation)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Image Rotation\n'''\nsample = cv2.imread('sample.jpg')\nheight, width = sample.shape[:2]",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nheight, width = sample.shape[:2]\nprint(height, width)\nrotation_matrix = cv2.getRotationMatrix2D(\n    (width/4, height/4), 50, .5)  # last one is scale it is used not to lose data while rotation\nrotated_image = cv2.warpAffine(sample, rotation_matrix, (width, height))\ncv2.imshow('normal_image', sample)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\ncv2.imshow('rotated_image', rotated_image)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "rotation_matrix",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "rotation_matrix = cv2.getRotationMatrix2D(\n    (width/4, height/4), 50, .5)  # last one is scale it is used not to lose data while rotation\nrotated_image = cv2.warpAffine(sample, rotation_matrix, (width, height))\ncv2.imshow('normal_image', sample)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\ncv2.imshow('rotated_image', rotated_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "rotated_image",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "rotated_image = cv2.warpAffine(sample, rotation_matrix, (width, height))\ncv2.imshow('normal_image', sample)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\ncv2.imshow('rotated_image', rotated_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Image Transpose\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nprint(sample.shape)\ntransposed_image = cv2.transpose(sample)\nprint(transposed_image.shape)\ncv2.imshow('transposed', transposed_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image resizing\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "transposed_image",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "transposed_image = cv2.transpose(sample)\nprint(transposed_image.shape)\ncv2.imshow('transposed', transposed_image)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image resizing\n'''\nsample = cv2.imread('sample.jpg')\n# interplotation",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\n# interplotation\ncv2.imshow('original image', sample)\n# linear interplotation--> size reduce karne ke liye\n# cubic interplotation--> size increae karne ke liye\nimage_reduced = cv2.resize(sample, None, fx=0.25, fy=0.25)\nimage_increased = cv2.resize(\n    sample, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\nimage_area_wise = cv2.resize(sample, (300, 300), interpolation=cv2.INTER_AREA)\ncv2.imshow('scaling--linear interpolation', image_reduced)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "image_reduced",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "image_reduced = cv2.resize(sample, None, fx=0.25, fy=0.25)\nimage_increased = cv2.resize(\n    sample, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\nimage_area_wise = cv2.resize(sample, (300, 300), interpolation=cv2.INTER_AREA)\ncv2.imshow('scaling--linear interpolation', image_reduced)\ncv2.waitKey(0)\ncv2.imshow('scaling--cubic interpolation', image_increased)\ncv2.waitKey(0)\ncv2.imshow(\"scaling--skewed size\", image_area_wise)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "image_increased",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "image_increased = cv2.resize(\n    sample, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\nimage_area_wise = cv2.resize(sample, (300, 300), interpolation=cv2.INTER_AREA)\ncv2.imshow('scaling--linear interpolation', image_reduced)\ncv2.waitKey(0)\ncv2.imshow('scaling--cubic interpolation', image_increased)\ncv2.waitKey(0)\ncv2.imshow(\"scaling--skewed size\", image_area_wise)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "image_area_wise",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "image_area_wise = cv2.resize(sample, (300, 300), interpolation=cv2.INTER_AREA)\ncv2.imshow('scaling--linear interpolation', image_reduced)\ncv2.waitKey(0)\ncv2.imshow('scaling--cubic interpolation', image_increased)\ncv2.waitKey(0)\ncv2.imshow(\"scaling--skewed size\", image_area_wise)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Image Pyramid",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nsmaller = cv2.pyrDown(sample)\nlarger = cv2.pyrUp(sample)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('smaller image', smaller)\ncv2.waitKey(0)\ncv2.imshow('larger image', larger)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "smaller",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "smaller = cv2.pyrDown(sample)\nlarger = cv2.pyrUp(sample)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('smaller image', smaller)\ncv2.waitKey(0)\ncv2.imshow('larger image', larger)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "larger",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "larger = cv2.pyrUp(sample)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('smaller image', smaller)\ncv2.waitKey(0)\ncv2.imshow('larger image', larger)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# Image cropping",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nheight, width = sample.shape[:2]\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\n# strating parameters of top left\nstart_row, start_col = int(height*.25), int(width*.25)\n# ending parameters of right bottom\nend_row, end_col = int(height*.75), int(width*.75)\ncropped = sample[start_row:end_row, start_col:end_col]\ncv2.imshow('cropped', cropped)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "cropped",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "cropped = sample[start_row:end_row, start_col:end_col]\ncv2.imshow('cropped', cropped)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image arithmetics\n'''\nsample = cv2.imread('sample.jpg')\ncv2.imshow('original image', sample)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\ncv2.imshow('original image', sample)\ncv2.waitKey(0)\nmat = np.ones(sample.shape, dtype=\"uint8\")*100\nadd = cv2.add(sample, mat)\ncv2.imshow(\"added\", add)\ncv2.waitKey(0)\nsub = cv2.subtract(sample, mat)\ncv2.imshow(\"substracted\", sub)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "mat",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "mat = np.ones(sample.shape, dtype=\"uint8\")*100\nadd = cv2.add(sample, mat)\ncv2.imshow(\"added\", add)\ncv2.waitKey(0)\nsub = cv2.subtract(sample, mat)\ncv2.imshow(\"substracted\", sub)\ncv2.waitKey(0)\nmul = cv2.multiply(sample, mat)\ncv2.imshow(\"multiplues\", mul)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "add",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "add = cv2.add(sample, mat)\ncv2.imshow(\"added\", add)\ncv2.waitKey(0)\nsub = cv2.subtract(sample, mat)\ncv2.imshow(\"substracted\", sub)\ncv2.waitKey(0)\nmul = cv2.multiply(sample, mat)\ncv2.imshow(\"multiplues\", mul)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sub",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sub = cv2.subtract(sample, mat)\ncv2.imshow(\"substracted\", sub)\ncv2.waitKey(0)\nmul = cv2.multiply(sample, mat)\ncv2.imshow(\"multiplues\", mul)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image bitwise operations\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "mul",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "mul = cv2.multiply(sample, mat)\ncv2.imshow(\"multiplues\", mul)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image bitwise operations\n'''\nsquare = np.zeros((300, 300), np.uint8)\ncv2.rectangle(square, (50, 50), (250, 250), 255, -1)\ncv2.imshow(\"square\", square)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "square",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "square = np.zeros((300, 300), np.uint8)\ncv2.rectangle(square, (50, 50), (250, 250), 255, -1)\ncv2.imshow(\"square\", square)\ncv2.waitKey(0)\nellipse = np.zeros((300, 300), np.uint8)\ncv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\ncv2.imshow(\"ellipse\", ellipse)\ncv2.waitKey(0)\nAnd = cv2.bitwise_and(square, ellipse)\ncv2.imshow(\"and\", And)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "ellipse",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "ellipse = np.zeros((300, 300), np.uint8)\ncv2.ellipse(ellipse, (150, 150), (150, 150), 30, 0, 180, 255, -1)\ncv2.imshow(\"ellipse\", ellipse)\ncv2.waitKey(0)\nAnd = cv2.bitwise_and(square, ellipse)\ncv2.imshow(\"and\", And)\ncv2.waitKey(0)\nOr = cv2.bitwise_or(square, ellipse)\ncv2.imshow(\"Or\", Or)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "And",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "And = cv2.bitwise_and(square, ellipse)\ncv2.imshow(\"and\", And)\ncv2.waitKey(0)\nOr = cv2.bitwise_or(square, ellipse)\ncv2.imshow(\"Or\", Or)\ncv2.waitKey(0)\nxor = cv2.bitwise_xor(square, ellipse)\ncv2.imshow(\"xor\", xor)\ncv2.waitKey(0)\nNot = cv2.bitwise_not(square, ellipse)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "Or",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "Or = cv2.bitwise_or(square, ellipse)\ncv2.imshow(\"Or\", Or)\ncv2.waitKey(0)\nxor = cv2.bitwise_xor(square, ellipse)\ncv2.imshow(\"xor\", xor)\ncv2.waitKey(0)\nNot = cv2.bitwise_not(square, ellipse)\ncv2.imshow(\"Not\",Not)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "xor",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "xor = cv2.bitwise_xor(square, ellipse)\ncv2.imshow(\"xor\", xor)\ncv2.waitKey(0)\nNot = cv2.bitwise_not(square, ellipse)\ncv2.imshow(\"Not\",Not)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image blurring options\n'''sample = cv2.imread('sample.jpg')",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "Not",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "Not = cv2.bitwise_not(square, ellipse)\ncv2.imshow(\"Not\",Not)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image blurring options\n'''sample = cv2.imread('sample.jpg')\ncv2.imshow('original', sample)\ncv2.waitKey(0)\n# creating 3*3 kernal",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "'''sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "'''sample = cv2.imread('sample.jpg')\ncv2.imshow('original', sample)\ncv2.waitKey(0)\n# creating 3*3 kernal\n# filter matrix->ye image se pass karvayenge--> to blur image aa jayega\nkernel_3 = np.ones((3, 3), np.float32)/9\nprint(kernel_3)\n# kernal sirf odd no. me hi kr sakte hai\nkernel_7 = np.ones((7, 7), np.float32)/49\nprint(kernel_7)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "kernel_3",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "kernel_3 = np.ones((3, 3), np.float32)/9\nprint(kernel_3)\n# kernal sirf odd no. me hi kr sakte hai\nkernel_7 = np.ones((7, 7), np.float32)/49\nprint(kernel_7)\n# we use cv2.filter2d to convolve the kernal with an image\n# blurred = cv2.filter2D(sample, -1, kernel_3)\nblurred = cv2.filter2D(sample, -1, kernel_7)\ncv2.imshow(\"3*3 blurr effect\", blurred)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "kernel_7",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "kernel_7 = np.ones((7, 7), np.float32)/49\nprint(kernel_7)\n# we use cv2.filter2d to convolve the kernal with an image\n# blurred = cv2.filter2D(sample, -1, kernel_3)\nblurred = cv2.filter2D(sample, -1, kernel_7)\ncv2.imshow(\"3*3 blurr effect\", blurred)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image smoothning",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "blurred",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "blurred = cv2.filter2D(sample, -1, kernel_7)\ncv2.imshow(\"3*3 blurr effect\", blurred)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image smoothning\n'''\nsample = cv2.imread('sample.jpg')\ncv2.imshow('original image', sample)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\ncv2.imshow('original image', sample)\ncv2.waitKey(0)\n# averaging is done by convolving th eimag ewith a normal box filter,\n# this takes thwe pixal under the box and replace the central element\n# box size need to odd and positive\nblur = cv2.blur(sample, (3, 3))\ncv2.imshow('box blur image', blur)\ncv2.waitKey(0)\n# gaussian blurred -->lighweight hai box se aur blur bhi jayada deta hai and smoothning bhi",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "blur",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "blur = cv2.blur(sample, (3, 3))\ncv2.imshow('box blur image', blur)\ncv2.waitKey(0)\n# gaussian blurred -->lighweight hai box se aur blur bhi jayada deta hai and smoothning bhi\ngaussian_blur = cv2.GaussianBlur(sample, (7, 7), 0)  # 0 is standar deviation\ncv2.imshow('gaussian blur image', gaussian_blur)\ncv2.waitKey(0)\n# median blur\n# take median of all the pixals under the kernal area and central element is replaced with median  values -->\n# sare elements ka median calculate karta hai aur jo value aayegi wo center me rakh dega pixal ke",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "gaussian_blur",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "gaussian_blur = cv2.GaussianBlur(sample, (7, 7), 0)  # 0 is standar deviation\ncv2.imshow('gaussian blur image', gaussian_blur)\ncv2.waitKey(0)\n# median blur\n# take median of all the pixals under the kernal area and central element is replaced with median  values -->\n# sare elements ka median calculate karta hai aur jo value aayegi wo center me rakh dega pixal ke\nmedian_blur = cv2.medianBlur(sample, 5)  # 0 is standar deviation\ncv2.imshow('median blur image', median_blur)\ncv2.waitKey(0)\n# bilateral filter --> most effective but heavy graphics card needed",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "median_blur",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "median_blur = cv2.medianBlur(sample, 5)  # 0 is standar deviation\ncv2.imshow('median blur image', median_blur)\ncv2.waitKey(0)\n# bilateral filter --> most effective but heavy graphics card needed\n# sigma color and sigma place\nbilateral = cv2.bilateralFilter(sample, 9, 75, 75)\ncv2.imshow('bilateral blur image', bilateral)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "bilateral",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "bilateral = cv2.bilateralFilter(sample, 9, 75, 75)\ncv2.imshow('bilateral blur image', bilateral)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n'''\n# image edge detection\n'''\nsample = cv2.imread('sample.jpg', 0)\nheight, width = sample.shape[:2]\n# 1.sobel technique--> very poor results-->too much noise",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg', 0)\nheight, width = sample.shape[:2]\n# 1.sobel technique--> very poor results-->too much noise\nsobel_x = cv2.Sobel(sample, cv2.CV_64F, 1, 0, ksize=5)\nsobel_y = cv2.Sobel(sample, cv2.CV_64F, 0, 1, ksize=5)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('sobel x', sobel_x)\ncv2.waitKey(0)\ncv2.imshow('sobel y', sobel_y)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sobel_x",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sobel_x = cv2.Sobel(sample, cv2.CV_64F, 1, 0, ksize=5)\nsobel_y = cv2.Sobel(sample, cv2.CV_64F, 0, 1, ksize=5)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('sobel x', sobel_x)\ncv2.waitKey(0)\ncv2.imshow('sobel y', sobel_y)\ncv2.waitKey(0)\nsobel_xor = cv2.bitwise_or(sobel_x, sobel_y)\ncv2.imshow('sobel_xor image', sobel_xor)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sobel_y",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sobel_y = cv2.Sobel(sample, cv2.CV_64F, 0, 1, ksize=5)\ncv2.imshow('normal image', sample)\ncv2.waitKey(0)\ncv2.imshow('sobel x', sobel_x)\ncv2.waitKey(0)\ncv2.imshow('sobel y', sobel_y)\ncv2.waitKey(0)\nsobel_xor = cv2.bitwise_or(sobel_x, sobel_y)\ncv2.imshow('sobel_xor image', sobel_xor)\ncv2.waitKey(0)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sobel_xor",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sobel_xor = cv2.bitwise_or(sobel_x, sobel_y)\ncv2.imshow('sobel_xor image', sobel_xor)\ncv2.waitKey(0)\n# to enhance the result use laplacian-->but also consist of noise\nlaplacian = cv2.Laplacian(sample, cv2.CV_64F)\ncv2.imshow('laplacian edge detection', laplacian)\ncv2.waitKey(0)\n# canny edge detection--> best in the class\n# uses gradient valures as threshold\ncanny = cv2.Canny(sample, 20, 150)",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "laplacian",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "laplacian = cv2.Laplacian(sample, cv2.CV_64F)\ncv2.imshow('laplacian edge detection', laplacian)\ncv2.waitKey(0)\n# canny edge detection--> best in the class\n# uses gradient valures as threshold\ncanny = cv2.Canny(sample, 20, 150)\ncv2.imshow('canny edge detection', canny)\ncv2.waitKey(0)\n'''\nsample = cv2.imread('sample.jpg')",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "canny",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "canny = cv2.Canny(sample, 20, 150)\ncv2.imshow('canny edge detection', canny)\ncv2.waitKey(0)\n'''\nsample = cv2.imread('sample.jpg')\nlaplacian = cv2.Laplacian(sample, cv2.CV_64F).var()\nprint(laplacian)\n# cv2.imshow('laplacian edge detection', laplacian)\ncv2.waitKey(0)\ndt = {'laplacian': sample}",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "sample",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "sample = cv2.imread('sample.jpg')\nlaplacian = cv2.Laplacian(sample, cv2.CV_64F).var()\nprint(laplacian)\n# cv2.imshow('laplacian edge detection', laplacian)\ncv2.waitKey(0)\ndt = {'laplacian': sample}\ncv2.imshow(\"op image\", sample)\nprint(dt['laplacian'])\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "laplacian",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "laplacian = cv2.Laplacian(sample, cv2.CV_64F).var()\nprint(laplacian)\n# cv2.imshow('laplacian edge detection', laplacian)\ncv2.waitKey(0)\ndt = {'laplacian': sample}\ncv2.imshow(\"op image\", sample)\nprint(dt['laplacian'])\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    },
    {
        "label": "dt",
        "kind": 5,
        "importPath": "opencv_notes",
        "description": "opencv_notes",
        "peekOfCode": "dt = {'laplacian': sample}\ncv2.imshow(\"op image\", sample)\nprint(dt['laplacian'])\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
        "detail": "opencv_notes",
        "documentation": {}
    }
]